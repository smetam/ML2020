{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронные сети\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "В этом домашнем задании можно использовать готовые классы библиотек PyTorch, Keras, TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (4 балла)\n",
    "\n",
    "Создайте сеть из трех сверточных слоев по 8 сверток 3х3 и двух полносвязных слоев по 64 нейрона. \n",
    "\n",
    "Обучите сеть на датасете mnist с тремя разными функциями активации в слоях (sigmoid, tanh, ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import string\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist_dataset(path_to_csv):\n",
    "    # Возвращает пару из X и y. X - массив векторов. y - соответствующие векторам метки\n",
    "    df = shuffle(pd.read_csv(path_to_csv))\n",
    "    y = df['label'].values\n",
    "    X = df.drop('label', axis=1).values\n",
    "    return X, y\n",
    "\n",
    "def train_test_split(X, y, ratio=0.8):\n",
    "    n = int(len(y) * ratio)\n",
    "    return X[:n], y[:n], X[n:], y[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 784)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X, y = read_mnist_dataset('hw1/mnist.csv')\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_mode(activation):\n",
    "    batch_size = 256\n",
    "    epochs = 5\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, kernel_size=(3, 3), activation=activation, input_shape=input_shape))\n",
    "    model.add(Conv2D(8, (3, 3), activation=activation))\n",
    "    model.add(Conv2D(8, (3, 3), activation=activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=activation))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 3s 400us/step - loss: 1.1853 - accuracy: 0.6219 - val_loss: 0.5106 - val_accuracy: 0.8420\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 2s 247us/step - loss: 0.3297 - accuracy: 0.9024 - val_loss: 0.4021 - val_accuracy: 0.8620\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 2s 253us/step - loss: 0.1998 - accuracy: 0.9404 - val_loss: 0.2721 - val_accuracy: 0.9160\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 2s 258us/step - loss: 0.1393 - accuracy: 0.9575 - val_loss: 0.1647 - val_accuracy: 0.9475\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 2s 240us/step - loss: 0.0979 - accuracy: 0.9712 - val_loss: 0.1995 - val_accuracy: 0.9365\n",
      "Test loss: 0.19950240260362626\n",
      "Test accuracy: 0.9365000128746033\n"
     ]
    }
   ],
   "source": [
    "activation_mode('relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 5s 573us/step - loss: 2.3320 - accuracy: 0.1075 - val_loss: 2.3203 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 4s 481us/step - loss: 2.3053 - accuracy: 0.1023 - val_loss: 2.3064 - val_accuracy: 0.1045\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 4s 476us/step - loss: 2.3036 - accuracy: 0.1090 - val_loss: 2.3032 - val_accuracy: 0.1130\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 4s 448us/step - loss: 2.3029 - accuracy: 0.1088 - val_loss: 2.3014 - val_accuracy: 0.1130\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 2.3022 - accuracy: 0.1130 - val_loss: 2.3054 - val_accuracy: 0.1035\n",
      "Test loss: 2.305407880783081\n",
      "Test accuracy: 0.10350000113248825\n"
     ]
    }
   ],
   "source": [
    "activation_mode('sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 5s 587us/step - loss: 0.7468 - accuracy: 0.7900 - val_loss: 0.3755 - val_accuracy: 0.8895\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 4s 485us/step - loss: 0.3116 - accuracy: 0.9118 - val_loss: 0.2683 - val_accuracy: 0.9225\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 4s 455us/step - loss: 0.2360 - accuracy: 0.9325 - val_loss: 0.2569 - val_accuracy: 0.9305\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 4s 460us/step - loss: 0.1900 - accuracy: 0.9449 - val_loss: 0.1988 - val_accuracy: 0.9455\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 4s 459us/step - loss: 0.1611 - accuracy: 0.9555 - val_loss: 0.2092 - val_accuracy: 0.9350\n",
      "Test loss: 0.20918868008255959\n",
      "Test accuracy: 0.9350000023841858\n"
     ]
    }
   ],
   "source": [
    "activation_mode('tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 (6 баллов)\n",
    "\n",
    "Достигните точности 87% на test датасете notMNIST.\n",
    "\n",
    "Архитектура сети может быть любая. Можно использовать Data Augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_not_mnist(letter2label):\n",
    "    image_arrays = []\n",
    "    labels = []\n",
    "    \n",
    "    dataset_path = pathlib.Path('hw1/notMNIST_small')\n",
    "    for letter, label in letter2label.items():\n",
    "        for image_path in (dataset_path / letter).glob('**/*.png'):\n",
    "            img = load_img(str(image_path))\n",
    "            x = img_to_array(img)\n",
    "            image_arrays.append(x)\n",
    "            labels.append(label)\n",
    "    X = np.array(image_arrays)\n",
    "    y = np.array(labels)\n",
    "    # shuffle\n",
    "    n = y.size\n",
    "    idx = np.random.choice(n, n, replace=False)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "letters = list(string.ascii_uppercase[:10])\n",
    "letter2label = dict(zip(letters, range(10)))\n",
    "label2letter = dict(zip(range(10), letters))\n",
    "\n",
    "X, y = read_not_mnist(letter2label)\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "input_shape = X_train.shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14979 samples, validate on 3745 samples\n",
      "Epoch 1/10\n",
      "14979/14979 [==============================] - 25s 2ms/step - loss: 0.7393 - accuracy: 0.7740 - val_loss: 0.3106 - val_accuracy: 0.9031\n",
      "Epoch 2/10\n",
      "14979/14979 [==============================] - 24s 2ms/step - loss: 0.3456 - accuracy: 0.9014 - val_loss: 0.2663 - val_accuracy: 0.9178\n",
      "Epoch 3/10\n",
      "14979/14979 [==============================] - 25s 2ms/step - loss: 0.2794 - accuracy: 0.9158 - val_loss: 0.2371 - val_accuracy: 0.9303\n",
      "Epoch 4/10\n",
      "14979/14979 [==============================] - 24s 2ms/step - loss: 0.2325 - accuracy: 0.9300 - val_loss: 0.2335 - val_accuracy: 0.9327\n",
      "Epoch 5/10\n",
      "14979/14979 [==============================] - 25s 2ms/step - loss: 0.2119 - accuracy: 0.9358 - val_loss: 0.2344 - val_accuracy: 0.9300\n",
      "Epoch 6/10\n",
      "14979/14979 [==============================] - 24s 2ms/step - loss: 0.1882 - accuracy: 0.9412 - val_loss: 0.2193 - val_accuracy: 0.9402\n",
      "Epoch 7/10\n",
      "14979/14979 [==============================] - 24s 2ms/step - loss: 0.1663 - accuracy: 0.9484 - val_loss: 0.2165 - val_accuracy: 0.9367\n",
      "Epoch 8/10\n",
      "14979/14979 [==============================] - 24s 2ms/step - loss: 0.1522 - accuracy: 0.9505 - val_loss: 0.2107 - val_accuracy: 0.9399\n",
      "Epoch 9/10\n",
      "14979/14979 [==============================] - 24s 2ms/step - loss: 0.1381 - accuracy: 0.9554 - val_loss: 0.2137 - val_accuracy: 0.9389\n",
      "Epoch 10/10\n",
      "14979/14979 [==============================] - 24s 2ms/step - loss: 0.1261 - accuracy: 0.9580 - val_loss: 0.2144 - val_accuracy: 0.9423\n",
      "Test loss: 0.21440169622626426\n",
      "Test accuracy: 0.9423230886459351\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
