{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронные сети\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "В этом домашнем задании можно использовать готовые классы библиотек PyTorch, Keras, TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (4 балла)\n",
    "\n",
    "Создайте сеть из трех сверточных слоев по 8 сверток 3х3 и двух полносвязных слоев по 64 нейрона. \n",
    "\n",
    "Обучите сеть на датасете mnist с тремя разными функциями активации в слоях (sigmoid, tanh, ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import string\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist_dataset(path_to_csv):\n",
    "    # Возвращает пару из X и y. X - массив векторов. y - соответствующие векторам метки\n",
    "    df = shuffle(pd.read_csv(path_to_csv))\n",
    "    y = df['label'].values\n",
    "    X = df.drop('label', axis=1).values\n",
    "    return X, y\n",
    "\n",
    "def train_test_split(X, y, ratio=0.8):\n",
    "    n = int(len(y) * ratio)\n",
    "    return X[:n], y[:n], X[n:], y[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 784)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X, y = read_mnist_dataset('hw1/mnist.csv')\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_mode(activation, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation=activation,\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.8142 - accuracy: 0.7398 - val_loss: 0.2453 - val_accuracy: 0.9245\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2454 - accuracy: 0.9266 - val_loss: 0.1713 - val_accuracy: 0.9450\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.1644 - accuracy: 0.9506 - val_loss: 0.1154 - val_accuracy: 0.9660\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.1154 - accuracy: 0.9635 - val_loss: 0.1020 - val_accuracy: 0.9715\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.0979 - accuracy: 0.9693 - val_loss: 0.0977 - val_accuracy: 0.9700\n",
      "Test loss: 0.09766330996900797\n",
      "Test accuracy: 0.9700000286102295\n"
     ]
    }
   ],
   "source": [
    "activation_mode('relu', keras.optimizers.Adadelta())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 2.6981 - accuracy: 0.0997 - val_loss: 2.3189 - val_accuracy: 0.1065\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 2.4553 - accuracy: 0.1004 - val_loss: 2.3033 - val_accuracy: 0.1130\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 2.4277 - accuracy: 0.0984 - val_loss: 2.3069 - val_accuracy: 0.1130\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 2.3880 - accuracy: 0.1034 - val_loss: 2.3055 - val_accuracy: 0.1130\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 2.3730 - accuracy: 0.1021 - val_loss: 2.3088 - val_accuracy: 0.0920\n",
      "Test loss: 2.3087642860412596\n",
      "Test accuracy: 0.09200000017881393\n"
     ]
    }
   ],
   "source": [
    "activation_mode('sigmoid', 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 21s 3ms/step - loss: 0.5773 - accuracy: 0.8200 - val_loss: 0.2599 - val_accuracy: 0.9215\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 22s 3ms/step - loss: 0.2391 - accuracy: 0.9291 - val_loss: 0.1827 - val_accuracy: 0.9425\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 20s 3ms/step - loss: 0.1707 - accuracy: 0.9480 - val_loss: 0.1538 - val_accuracy: 0.9545\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 20s 2ms/step - loss: 0.1344 - accuracy: 0.9561 - val_loss: 0.1333 - val_accuracy: 0.9635\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.0973 - accuracy: 0.9715 - val_loss: 0.1282 - val_accuracy: 0.9605\n",
      "Test loss: 0.12818317437171936\n",
      "Test accuracy: 0.9605000019073486\n"
     ]
    }
   ],
   "source": [
    "activation_mode('tanh', keras.optimizers.Adadelta())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 (6 баллов)\n",
    "\n",
    "Достигните точности 87% на test датасете notMNIST.\n",
    "\n",
    "Архитектура сети может быть любая. Можно использовать Data Augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_not_mnist(letter2label):\n",
    "    image_arrays = []\n",
    "    labels = []\n",
    "    \n",
    "    dataset_path = pathlib.Path('hw1/notMNIST_small')\n",
    "    for letter in letter2label:\n",
    "        for image_path in (dataset_path / letter).glob('**/*.png'):\n",
    "            img = load_img(str(image_path))\n",
    "            x = img_to_array(img)\n",
    "            image_arrays.append(x)\n",
    "            labels.append(letter2label[letter])\n",
    "    X = np.array(image_arrays)\n",
    "    y = np.array(labels)\n",
    "    # shuffle\n",
    "    n = y.size\n",
    "    idx = np.random.choice(n, n, replace=False)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "letters = list(string.ascii_uppercase[:10])\n",
    "letter2label = dict(zip(letters, range(10)))\n",
    "label2letter = dict(zip(range(10), letters))\n",
    "\n",
    "X, y = read_not_mnist(letter2label)\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "input_shape = X_train.shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14979 samples, validate on 3745 samples\n",
      "Epoch 1/5\n",
      "14979/14979 [==============================] - 23s 2ms/step - loss: 0.7355 - accuracy: 0.7739 - val_loss: 0.3227 - val_accuracy: 0.9095\n",
      "Epoch 2/5\n",
      "14979/14979 [==============================] - 21s 1ms/step - loss: 0.3348 - accuracy: 0.8994 - val_loss: 0.2359 - val_accuracy: 0.9279\n",
      "Epoch 3/5\n",
      "14979/14979 [==============================] - 21s 1ms/step - loss: 0.2660 - accuracy: 0.9205 - val_loss: 0.2374 - val_accuracy: 0.9332\n",
      "Epoch 4/5\n",
      "14979/14979 [==============================] - 21s 1ms/step - loss: 0.2260 - accuracy: 0.9290 - val_loss: 0.2484 - val_accuracy: 0.9284\n",
      "Epoch 5/5\n",
      "14979/14979 [==============================] - 21s 1ms/step - loss: 0.2018 - accuracy: 0.9382 - val_loss: 0.2074 - val_accuracy: 0.9431\n",
      "Test loss: 0.2073681864904262\n",
      "Test accuracy: 0.9431241750717163\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
